{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77917043",
   "metadata": {},
   "source": [
    "\n",
    "# Flask Backend for Emotionally Tuned AI Response\n",
    "\n",
    "This Jupyter Notebook contains a Flask backend that integrates **Google's Gemini AI** with **Psi Theory parameters** to generate emotionally aware responses. \n",
    "\n",
    "### Features:\n",
    "- Integrates **LangChain Memory** for conversation context.\n",
    "- Implements **Google Gemini AI** for text generation.\n",
    "- Computes **sadness and anger levels** based on user input and past conversation.\n",
    "\n",
    "## Prerequisites\n",
    "Before running the Flask app, ensure you have the following dependencies installed:\n",
    "\n",
    "```bash\n",
    "pip install google-generativeai python-dotenv langchain\n",
    "```\n",
    "\n",
    "Make sure to set up your environment variables in a `.env` file:\n",
    "\n",
    "```\n",
    "GEMINI_API_KEY=your_api_key_here\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1392806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from flask import Flask, request, jsonify\n",
    "from flask_cors import CORS\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bfd5c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "CORS(app)  # Enable CORS for all routes\n",
    "\n",
    "# Configure Gemini API\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if not gemini_api_key:\n",
    "    raise ValueError(\"GEMINI_API_KEY is not set in the environment variables!\")\n",
    "\n",
    "genai.configure(api_key=gemini_api_key)\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "\n",
    "# Initialize LangChain memory\n",
    "memory = ConversationBufferMemory()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36482132",
   "metadata": {},
   "source": [
    "\n",
    "## Emotion Level Calculation\n",
    "\n",
    "The function below computes **sadness and anger levels** based on **Psi Theory parameters** and **conversation context**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bfaadcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_emotion_levels(valence_level, arousal_level, selection_threshold, resolution_level, conversation_history):\n",
    "    \"\"\"\n",
    "    Calculate sadness and anger levels based on Psi Theory parameters and conversation context.\n",
    "    \n",
    "    Args:\n",
    "        valence_level (int): Valence level (0-7).\n",
    "        arousal_level (int): Arousal level (0-7).\n",
    "        selection_threshold (int): Selection threshold (0-7).\n",
    "        resolution_level (int): Resolution level (0-7).\n",
    "        conversation_history (str): The conversation history as a string.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (sadness_level, anger_level) on a scale of 1-5.\n",
    "    \"\"\"\n",
    "    sadness_level = 1  # Default to low sadness\n",
    "    anger_level = 1  # Default to low anger\n",
    "\n",
    "    # Base calculations based on Psi Theory parameters\n",
    "    if valence_level < 4:  # Negative valence\n",
    "        sadness_level += 1\n",
    "        if arousal_level < 4:  # Low arousal\n",
    "            sadness_level += 1\n",
    "        if resolution_level < 4:  # Low resolution\n",
    "            sadness_level += 1\n",
    "\n",
    "    if valence_level < 4:  # Negative valence\n",
    "        if arousal_level > 5:  # High arousal\n",
    "            anger_level += 2\n",
    "        if selection_threshold > 5:  # High selection threshold\n",
    "            anger_level += 1\n",
    "        if resolution_level < 4:  # Low resolution\n",
    "            anger_level += 1\n",
    "\n",
    "    # Incorporate conversation context\n",
    "    if \"fail\" in conversation_history.lower() or \"can't\" in conversation_history.lower():\n",
    "        sadness_level += 1  # Increase sadness if failure is mentioned\n",
    "    if \"success\" in conversation_history.lower() or \"achieved\" in conversation_history.lower():\n",
    "        sadness_level -= 1  # Decrease sadness if success is mentioned\n",
    "\n",
    "    if \"obstacle\" in conversation_history.lower() or \"conflict\" in conversation_history.lower():\n",
    "        anger_level += 1  # Increase anger if obstacles are mentioned\n",
    "    if \"calm\" in conversation_history.lower() or \"resolved\" in conversation_history.lower():\n",
    "        anger_level -= 1  # Decrease anger if resolution is mentioned\n",
    "\n",
    "    # Ensure levels are within 1-5 range\n",
    "    sadness_level = min(max(sadness_level, 1), 5)\n",
    "    anger_level = min(max(anger_level, 1), 5)\n",
    "\n",
    "    return sadness_level, anger_level\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d105a1",
   "metadata": {},
   "source": [
    "\n",
    "## AI Response Generation\n",
    "\n",
    "This function generates a Gemini AI response based on **Psi Theory parameters** and **emotion levels**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5de4c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_psi_tuned_response(\n",
    "    valence_level,\n",
    "    arousal_level,\n",
    "    selection_threshold,\n",
    "    resolution_level,\n",
    "    goal_directedness,\n",
    "    securing_rate,\n",
    "    message,\n",
    "    conversation_history,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates a Gemini response tuned to the specified Psi Theory parameters and emotional state.\n",
    "    \n",
    "    Args:\n",
    "        valence_level (int): Valence level (0-7).\n",
    "        arousal_level (int): Arousal level (0-7).\n",
    "        selection_threshold (int): Selection threshold (0-7).\n",
    "        resolution_level (int): Resolution level (0-7).\n",
    "        goal_directedness (int): Goal-directedness (0-7).\n",
    "        securing_rate (int): Securing rate (0-7).\n",
    "        message (str): User input message.\n",
    "        conversation_history (str): The conversation history as a string.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (response, sadness_level, anger_level)\n",
    "    \"\"\"\n",
    "    # Calculate sadness and anger levels\n",
    "    sadness_level, anger_level = calculate_emotion_levels(\n",
    "        valence_level, arousal_level, selection_threshold, resolution_level, conversation_history\n",
    "    )\n",
    "\n",
    "    # Determine emotional tone based on sadness and anger levels\n",
    "    emotional_tone = \"\"\n",
    "    if sadness_level >= 4:\n",
    "        emotional_tone += \"Respond in an empathetic and supportive manner. \"\n",
    "    if anger_level >= 4:\n",
    "        emotional_tone += \"Respond in an assertive and direct manner. \"\n",
    "\n",
    "    # Create a prompt that incorporates Psi Theory parameters, emotional tone, and conversation history\n",
    "    prompt = f\"\"\"\n",
    "    Remember the previous conversation and respond to the following message while considering these parameters of Dornerâ€™s Psi Theory, each on a scale of 1 to 7:\n",
    "    Do not mention about the parameters\n",
    "    who ever asked you about your identity describe your self as Yohannes's chat assistant prompted by him.\n",
    "    Conversation History:\n",
    "    {conversation_history}\n",
    "\n",
    "    * **Valence Level:** {valence_level} (Higher values indicate more positive affect.)\n",
    "    * **Arousal Level:** {arousal_level} (Higher values indicate greater alertness and readiness for action.)\n",
    "    * **Selection Threshold:** {selection_threshold} (Higher values indicate stronger focus and less distractibility.)\n",
    "    * **Resolution Level:** {resolution_level} (Higher values indicate more detailed and accurate perception.)\n",
    "    * **Goal-Directedness:** {goal_directedness} (Higher values indicate stronger motivation and persistence towards goals.)\n",
    "    * **Securing Rate:** {securing_rate} (Higher values indicate more frequent environmental scanning and reflection.)\n",
    "\n",
    "    Message: {message}\n",
    "\n",
    "    **Important Notes:**\n",
    "    * Just give me the answer to my question based on the parameters.\n",
    "    * {emotional_tone}\n",
    "    * Ensure your response is consistent with the specified emotional and motivational states.\n",
    "\n",
    "    **Gemini Response:**\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Generate a response from Gemini\n",
    "        response = model.generate_content(prompt)\n",
    "        gemini_response = response.text\n",
    "\n",
    "        # Update memory with the current user input and Gemini response\n",
    "        memory.save_context({\"input\": message}, {\"output\": gemini_response})\n",
    "\n",
    "        return gemini_response, sadness_level, anger_level\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response: {e}\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fca7c8",
   "metadata": {},
   "source": [
    "\n",
    "## Running the Model with example\n",
    "\n",
    "Run the following command in the terminal to start the server:\n",
    "\n",
    "```bash\n",
    "python your_notebook_name.py\n",
    "```\n",
    "\n",
    "Or, if using **Jupyter Notebook**, run the cell below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "475c38f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"I'm Yohannes's chat assistant, prompted by him.\\n\", 2, 3)\n"
     ]
    }
   ],
   "source": [
    "print(generate_psi_tuned_response(\n",
    "    1,\n",
    "    7,\n",
    "    3,\n",
    "    5,\n",
    "    4,\n",
    "    4,\n",
    "    'who are you',\n",
    "    '',\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
